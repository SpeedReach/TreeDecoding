{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096e9876-50c2-4027-b3a1-c8b4fdbcee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from modeling_llama import LlamaForCausalLM\n",
    "from transformers import LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e86d74-e7d4-4f1e-b32a-0e760c2797bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.19it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # Adjust based on your access\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b49d80-f432-4907-bcb6-70afe0ff4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "945ff9d5-cd6b-456d-a958-29ceae59879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 5])\n",
      "Sentence 1: Once upon a time , there was a little girl who loved to read. She loved to read so much that she would read anything she could get her hands on. She would read the cereal box, the back of the cereal box, the back of the cereal box again, and then she would read the cereal box again. She would read the cereal box so much that she would read the cereal box until she was sick of reading the cereal box.\n",
      "Sentence 2: Once upon a time there was a little girl who loved to read. She loved to read so much that she would read anything she could get her hands on. She would read the back of cereal boxes, the ingredients on the side of the box, the instructions on the back of the box, the instructions on the side of the box, the instructions on the back of the box, the instructions on the side of the box, the instructions on the back of the box, the instructions on the side\n",
      "Sentence 3: Once upon a time in a land far, far away, there was a little girl who loved to read. She loved to read so much that she would read anything she could get her hands on. She would read the cereal box, the back of the cereal box, the back of the cereal box that was on the floor, the back of the cereal box that was on the floor that was on the floor, the back of the cereal box that was on the floor\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_next_tokens(model, tokenizer, input_ids, num_passes=100):\n",
    "    device = model.device\n",
    "    past_key_values = None\n",
    "    outputs = []\n",
    "    input_len = input_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # First pass\n",
    "        first_outputs = model(input_ids, past_key_values=past_key_values, use_cache=True)\n",
    "        next_token_logits = first_outputs.logits[:, -1, :]\n",
    "        past_key_values = first_outputs.past_key_values\n",
    "        next_token_scores = F.log_softmax(next_token_logits, dim=-1)\n",
    "        next_token_scores, next_tokens = torch.topk(\n",
    "            next_token_scores, 3, dim=1, largest=True, sorted=True\n",
    "        )\n",
    "        outputs.append(next_tokens[0])\n",
    "\n",
    "        # Subsequent passes\n",
    "        for i in range(1, num_passes):\n",
    "            position_ids = torch.tensor([[i + input_len-1, i + input_len-1, i + input_len-1]], device=device)\n",
    "            \n",
    "            attention_mask_length = input_len + i * 3\n",
    "            attention_mask = torch.zeros((1, 1, 3, attention_mask_length), device=device, dtype=torch.float16)\n",
    "            attention_mask[0, 0, :, :input_len] = 0\n",
    "            for j in range(i):\n",
    "                start_idx = input_len + j * 3\n",
    "                attention_mask[0, 0, :, start_idx:start_idx+3] = torch.tensor([[0, -65504, -65504],\n",
    "                                                                               [-65504, 0, -65504],\n",
    "                                                                               [-65504, -65504, 0]], device=device)\n",
    "\n",
    "            #print(position_ids, attention_mask)\n",
    "\n",
    "            pass_outputs = model(next_tokens, past_key_values=past_key_values, \n",
    "                                 position_ids=position_ids, attention_mask=attention_mask, use_cache=True)\n",
    "            next_token_logits = pass_outputs.logits[:, -3:, :]\n",
    "            past_key_values = pass_outputs.past_key_values\n",
    "            \n",
    "            next_tokens = torch.argmax(next_token_logits, dim=-1)\n",
    "            outputs.append(next_tokens[0])\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# Example usage\n",
    "input_ids = tokenizer.encode(\"Once upon a time\", return_tensors=\"pt\").to(model.device)\n",
    "print(f\"Input shape: {input_ids.shape}\")\n",
    "\n",
    "generated_outputs = generate_next_tokens(model, tokenizer, input_ids)\n",
    "stacked_tensor = torch.stack(generated_outputs)\n",
    "\n",
    "# Group elements by position\n",
    "grouped_tensors = [\n",
    "    stacked_tensor[:, 0],  # First elements\n",
    "    stacked_tensor[:, 1],  # Second elements\n",
    "    stacked_tensor[:, 2]   # Third elements\n",
    "]\n",
    "\n",
    "# Print the result\n",
    "for i, tensor in enumerate(grouped_tensors, 1):\n",
    "    print(f\"Sentence {i}: Once upon a time {tokenizer.decode(tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83025a3b-e3da-4bd7-972c-1e724b4337da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcb190-505f-497b-b3ad-e90dda4ed42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
